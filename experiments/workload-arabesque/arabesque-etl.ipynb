{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e55e7c12",
   "metadata": {},
   "source": [
    "# Arabesque Dataset ETL\n",
    "\n",
    "## Metadata\n",
    "\n",
    "|Parameter | Description |\n",
    "|----------|-------------|\n",
    "|limit_cores| CPU cores limit of the container. Sampled every 60 seconds.|\n",
    "|limit_utilization| The fraction of the CPU limit that is currently in use on the instance. This value cannot exceed 1 as usage cannot exceed the limit. Sampled every 60 seconds. After sampling, data is not visible for up to 240 seconds.|\n",
    "|request_cores|Number of CPU cores requested by the container. Sampled every 60 seconds. After sampling, data is not visible for up to 120 seconds.|\n",
    "|request_utilization|The fraction of the requested CPU that is currently in use on the instance. This value can be greater than 1 as usage can exceed the request. Sampled every 60 seconds. After sampling, data is not visible for up to 240 seconds.|\n",
    "|limit_bytes|Local ephemeral storage limit in bytes. Sampled every 60 seconds.|\n",
    "|request_bytes|Local ephemeral storage request in bytes. Sampled every 60 seconds.|\n",
    "|uptime|Time in seconds that the container has been running. Sampled every 60 seconds.|\n",
    "|||"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5dea1db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9862f94a",
   "metadata": {},
   "source": [
    "# Tupled Dataset\n",
    "## 1. Extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8e205a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('dataset-2/dataset_portfolio.pkl', 'rb') as f:\n",
    "    dataset = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efc6f08c",
   "metadata": {},
   "source": [
    "## 2. Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "20d0629d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the proper instances from dataset (cuz some of the instances have incomplete feature set)\n",
    "valid_containers = []\n",
    "for pod in dataset.keys():\n",
    "    if len(dataset[pod].keys()) == 13:\n",
    "        valid_containers.append(pod)\n",
    "\n",
    "\n",
    "final = {} \n",
    "\n",
    "# iterate on the dataset and transform each instance to the desired form\n",
    "for pod in dataset.keys():\n",
    "    if pod in valid_containers:\n",
    "        result = {}\n",
    "\n",
    "        # general info\n",
    "        namespace = pod[1]\n",
    "        pod_name =pod[2]\n",
    "        container = pod[3]\n",
    "\n",
    "        result[container] = {}\n",
    "        \"\"\"\n",
    "        cpu ETL info:\n",
    "            - fill the nan values with -1\n",
    "            - compute cpu usage\n",
    "            - store results in a numpy array\n",
    "        \"\"\"\n",
    "        \n",
    "        cpu_limit = dataset[pod][\"container/cpu/limit_cores\"].fillna(-1).to_numpy()\n",
    "        cpu_request = dataset[pod][\"container/cpu/request_cores\"].fillna(-1).to_numpy()\n",
    "        cpu_utilization = dataset[pod][\"container/cpu/request_cores\"].fillna(-1) *  dataset[pod][\"container/cpu/request_utilization\"].fillna(1)\n",
    "        cpu_utilization = cpu_utilization.to_numpy()\n",
    "\n",
    "\n",
    "        \"\"\"\n",
    "        memory ETL info:\n",
    "            - fill the nan values with -1\n",
    "            - store results in a numpy array\n",
    "        \"\"\"\n",
    "        mem_limit = dataset[pod][\"container/memory/limit_bytes\"].fillna(-1).to_numpy()\n",
    "        mem_request = dataset[pod][\"container/memory/request_bytes\"].fillna(-1).to_numpy()\n",
    "        mem_usage_evictable = dataset[pod][\"container/memory/used_bytes_{'memory_type': 'evictable'}\"].fillna(-1).to_numpy()\n",
    "        mem_usage_non = dataset[pod][\"container/memory/used_bytes_{'memory_type': 'non-evictable'}\"].fillna(-1).to_numpy()\n",
    "\n",
    "        \"\"\"\n",
    "        timestamp info:\n",
    "            - transform datetime to timestamp\n",
    "            - transform timestamp to intervals in seconds\n",
    "            - store results in a numpy array\n",
    "        \"\"\"\n",
    "        # timestamp\n",
    "        timestamp = dataset[pod].index\n",
    "\n",
    "        # datetime to timestamp (turn datetime to timestamp)\n",
    "        result[container][\"timestamp\"] = timestamp.values.astype(np.int64) // 10 ** 9\n",
    "        \n",
    "        # transform timestampt to intervals in seconds\n",
    "        result[container][\"timestamp\"] = result[container][\"timestamp\"] - np.amin(result[container][\"timestamp\"])\n",
    "\n",
    "        # add workload\n",
    "        result[container][\"workload\"] = [mem_usage_non, mem_usage_evictable, cpu_utilization]\n",
    "\n",
    "        # add limit\n",
    "        result[container][\"limit\"] = [mem_limit, cpu_limit]\n",
    "\n",
    "        # add request\n",
    "        result[container][\"request\"] = [mem_request, cpu_request]\n",
    "\n",
    "        # add to the dictionary\n",
    "        if final.get(namespace, None) is None:\n",
    "            final[namespace] = {}\n",
    "\n",
    "        if final[namespace].get(pod_name, None) is None:\n",
    "            final[namespace][pod_name] = {}\n",
    "\n",
    "\n",
    "        final[namespace][pod_name] = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "308c2bac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['qryfolio-cli-backtest-global-q9m8m-1716119528', 'qryfolio-cli-backtest-global-q9m8m-1177278544', 'qryfolio-cli-backtest-emea-4z5dg-384635719', 'qryfolio-cli-backtest-emea-4z5dg-3118974067', 'qryfolio-cli-backtest-bimb-wbtrt-3376620446', 'qryfolio-cli-backtest-bimb-wbtrt-1628592346', 'qryfolio-rebalance-global-d86j7-537827377', 'qryfolio-rebalance-global-d86j7-3379045925', 'qryfolio-rebalance-oas-h85zl-3154563979', 'qryfolio-rebalance-oas-h85zl-4114233401'])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final['qryfolio-daily'].keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05946be3",
   "metadata": {},
   "source": [
    "## 3. Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4575ca5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('arabesque.pickle', 'wb') as handle:\n",
    "    pickle.dump(final, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfcae466",
   "metadata": {},
   "source": [
    "# Nested Dataset\n",
    "## 1. Extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "58f33ddf",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('dataset-2/dataset_engine.pkl', 'rb') as f:\n",
    "    dataset = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e208f4d3",
   "metadata": {},
   "source": [
    "## 2. Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e1747173",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the proper instances from dataset (cuz some of the instances have incomplete feature set)\n",
    "valid_containers = []\n",
    "for pod in dataset['dev-compute-4']['engine'].keys():\n",
    "    if len(dataset['dev-compute-4']['engine'][pod]['main'].keys()) == 13:\n",
    "        valid_containers.append(pod)\n",
    "\n",
    "final = {} \n",
    "\n",
    "# iterate on the dataset and transform each instance to the desired form\n",
    "for pod in dataset['dev-compute-4']['engine'].keys():\n",
    "    result = {}\n",
    "    \n",
    "    # general info\n",
    "    namespace = 'engine'\n",
    "    pod_name = pod\n",
    "    container = 'main'\n",
    "\n",
    "    result[container] = {}\n",
    "\n",
    "    \n",
    "    # cpu info\n",
    "    cpu_limit = dataset['dev-compute-4']['engine'][pod]['main'][\"container/cpu/limit_cores\"].fillna(-1).to_numpy()\n",
    "    cpu_request = dataset['dev-compute-4']['engine'][pod]['main'][\"container/cpu/request_cores\"].fillna(-1).to_numpy()\n",
    "    cpu_utilization = dataset['dev-compute-4']['engine'][pod]['main'][\"container/cpu/request_cores\"].fillna(-1) *  dataset['dev-compute-4']['engine'][pod]['main'][\"container/cpu/request_utilization\"].fillna(1)\n",
    "    cpu_utilization = cpu_utilization.to_numpy()\n",
    "    \n",
    "    # memory info\n",
    "    mem_limit = dataset['dev-compute-4']['engine'][pod]['main'][\"container/memory/limit_bytes\"].fillna(-1).to_numpy()\n",
    "    mem_request = dataset['dev-compute-4']['engine'][pod]['main'][\"container/memory/request_bytes\"].fillna(-1).to_numpy()\n",
    "    mem_usage_evictable = dataset['dev-compute-4']['engine'][pod]['main'][\"container/memory/used_bytes_{'memory_type': 'evictable'}\"].fillna(-1).to_numpy()\n",
    "    mem_usage_non = dataset['dev-compute-4']['engine'][pod]['main'][\"container/memory/used_bytes_{'memory_type': 'non-evictable'}\"].fillna(-1).to_numpy()\n",
    "\n",
    "    # timestamp\n",
    "    timestamp = dataset['dev-compute-4']['engine'][pod]['main'].index\n",
    "    \n",
    "    # datetime to timestamp (turn datetime to timestamp)\n",
    "    result[container][\"timestamp\"] = timestamp.values.astype(np.int64) // 10 ** 9\n",
    "    \n",
    "    # change timestamp to interval\n",
    "    result[container][\"timestamp\"] = result[container][\"timestamp\"] - np.amin(result[container][\"timestamp\"])\n",
    "    \n",
    "    # add workload \n",
    "    result[container][\"workload\"] = [mem_usage_non, mem_usage_evictable, cpu_utilization]\n",
    "    \n",
    "    # add limit\n",
    "    result[container][\"limit\"] = [mem_limit, cpu_limit]\n",
    "    \n",
    "    # add request\n",
    "    result[container][\"request\"] = [mem_request, cpu_request]\n",
    "    \n",
    "    # add to the dictionary\n",
    "    if final.get(namespace, None) is None:\n",
    "        final[namespace] = {}\n",
    "   \n",
    "    if final[namespace].get(pod_name, None) is None:\n",
    "        final[namespace][pod_name] = {}\n",
    "        \n",
    "        \n",
    "    final[namespace][pod_name] = result\n",
    "\n",
    "# final['engine']['datasets-qbt8z-4024139702']['main']['workload']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9579b2e9",
   "metadata": {},
   "source": [
    "## 3. Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "be4798dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('engine.pickle', 'wb') as handle:\n",
    "    pickle.dump(final, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deleteme",
   "language": "python",
   "name": "deleteme"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
